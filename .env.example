# SAI Inference Service Configuration

# API Settings
SAI_HOST=0.0.0.0
SAI_PORT=8888
SAI_WORKERS=1

# SAINet2.1 Reference Configuration (from inf_yolo11m_SAINet2.1.py)
SAI_MODEL_DIR=models
SAI_DEFAULT_MODEL=sai_v2.1.pt
SAI_DEVICE=cpu  # or cuda, cuda:0
SAI_CONFIDENCE=0.15  # Reference: conf=0.15 (fire safety priority)
SAI_IOU_THRESHOLD=0.45
SAI_INPUT_SIZE=1920  # Reference: imgsz=1920 (SAINet2.1 optimized)

# Performance
SAI_BATCH_SIZE=1
SAI_MAX_QUEUE=100
SAI_CACHE_ENABLED=true
SAI_CACHE_TTL=300

# n8n Integration
SAI_API_KEY=your-secret-api-key
SAI_ALLOWED_ORIGINS=*

# Monitoring
SAI_ENABLE_METRICS=true
SAI_METRICS_PORT=9090
SAI_LOG_LEVEL=INFO

# Redis (optional)
SAI_REDIS_URL=redis://localhost:6379/0

# File Upload
SAI_MAX_UPLOAD=52428800  # 50MB
SAI_ALLOWED_EXTENSIONS=[".jpg",".jpeg",".png",".bmp",".tiff",".webp"]