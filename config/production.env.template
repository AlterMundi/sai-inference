# SAI Inference Service - Production Configuration Template
# Copy this file to /etc/sai-inference/production.env during installation

# Service Configuration
SAI_HOST=0.0.0.0
SAI_PORT=8888
SAI_WORKERS=1

# Model Configuration
SAI_MODEL_DIR=/opt/sai-inference/models
SAI_DEFAULT_MODEL=sai_v2.1.pt
SAI_DEVICE=cpu
SAI_INPUT_SIZE=1920
SAI_CONFIDENCE_THRESHOLD=0.15
SAI_IOU_THRESHOLD=0.45

# Performance
SAI_CACHE_SIZE=100
SAI_CACHE_TTL=300

# Logging
SAI_LOG_LEVEL=INFO
SAI_LOG_FILE=/var/log/sai-inference/service.log

# Security (uncomment and set if needed)
# SAI_API_KEY=your-secure-api-key-here

# Monitoring
SAI_HEALTH_CHECK_INTERVAL=30