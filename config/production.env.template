# SAI Inference Service - Production Configuration Template
# Copy this file to /etc/sai-inference/production.env during installation

# Service Configuration
SAI_HOST=0.0.0.0
SAI_PORT=8888
SAI_WORKERS=1

# Model Configuration
SAI_MODEL_DIR=/opt/sai-inference/models
SAI_DEFAULT_MODEL=last.pt
SAI_DEVICE=cuda
SAI_INPUT_SIZE=864
SAI_CONFIDENCE_THRESHOLD=0.13
SAI_IOU_THRESHOLD=0.4

# Logging
SAI_LOG_LEVEL=INFO
SAI_LOG_FILE=/var/log/sai-inference/service.log

# Security (uncomment and set if needed)
# SAI_API_KEY=your-secure-api-key-here

# Monitoring
SAI_HEALTH_CHECK_INTERVAL=30